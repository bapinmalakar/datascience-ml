ML algorithm types: 

1. Supervised learning: Going to teach computer how to do task
2. Unsupervised learning: Computer going to learn by self

Other type:
1. Reinforcement Learning
2. Recommender System

#Superviser Learning
Regression Problem: Try to find output of contiguous values  ex: price of hose
Classification Problem: Tyr to find output of Discrete Values(0 or 1) ex: Movie Like or Not, child class indentification

#Unsupervised Learning
1. Data are not labeld
2. We dont explained what each data point
3. We give data set, and ml try to find the structure of the data
4. In unsupervised we give data in different cluster, and ml try to predict the data into the different cluster
5. Known as Clustering algorithm
6. Google News use Cluster algorithom
7. Cluster Algorithm try to group the data, each group known as cluster

#Regression Problem with LinerRegression with Single X 
1. have training set
2. training set apply on learning algoritnm
3. Learning algorithm use h:function(hypothesis function) to predict traget(Y) and iput is features(X)
4. h(x) = Q0 + Q1(X),   Q0 is theta 0 and Q1 is theta 1, h(x) is linear function
5. Cost function: figure out best straight line into our data
6. Q0, Q1 are parameter
7. theta value may be (Q0, Q1) = (1.5, 0), (Q0, Q1) = (0, 0.5), (Q0, Q1) = (1, 0.5) 
8. now objective is findout the best parameter value
9. Choose the value of Q1,Q2 such taht h(x) give value near to Y of training data(X,Y)
10. Minimize Q0, Q1 such that h(x)-Y Square difference is minimum
11. Sum of (hi(x) - Y(i)) Square difference, i from 1 to n, where n is number of row(traing data size), let whole thing is T
12. So h(xi) = Q0 + Q1(xi),
13. Cost function is J(Q0, Q1) = (1/2N)(T)
14. This cost function is also known as Square Error Function

#Gradien Descent Algoritm
1. Use to find the value of Q1, Q2
2. And it will automatically find the best value
#Process
1. start with any value of Q0,Q1
2. Keep chnging value and evalute cost function J(Q0,Q1)
3. Stop when minimize the value of cost function J(Q0,Q1)

# Regression with multiple X
1. if i want to find y(roam price) using N-number of x (features i.e size, location, roam number, floor number etc), then I need to use Metrics and Vector
2. metric is a N dimensional(N= number of features) array, have all the fetures data
3. vetor is 1D array, have all target value respect to feaures

#Vector is a metrix with one column only (N X 1)
#Here this vector is N -Dimesional

#Predictin Formula
prediction = DataMetrics(metrics by X values) * Parameter Vector

#if X is more than 1 then
1. h(x) = Q0 + Q1(X1) + Q2(X2) + Q3(X3) + .... + QN(XN)
2. Each row is one columne


#Normal equation
Gradient Descent algorithm used to find Q, but this process is iterative proces. Fast even N is large, Need learning rate
We have another algorithm for find Q is Normal Equation by analytically, Slow if N is large, not required learning rate

#Classification Using Logistic Regression
Logistic Regression is binary Classification model, because it can classify only two class. In Logistic Regression it ensure that 
the output of (hQ) should be 0<=h(Q1)<=1
1. h(X) = g(Q^T X)
2. g(z) = 1/(1+e^-z), z is row number and this function known as sigmoid functio/logistic function
3. z is -inifinity, g(z) approach to 0, z is +inifinity then g(z) approach to 1
4. Decision Boundary
5. the line beteween Y=0 class and Y=1 class, means the line which divided class 0 and 1, known as decision boundary
6. Incase of linear data this line is straight line
7. incase of non-liner boundary decision line can any form, curve, circle etc.
7. For no-linear data we can use polynomial regression like used in linear regression